{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLl_c_YyMe2i"
      },
      "source": [
        "Post-Generation Hallucination Detection using Retrieval-Grounded Fact Verification\n",
        "\n",
        "Objective\n",
        "\n",
        "Build a system that automatically detects whether an LLM-generated answer is factually supported, partially supported, or hallucinated by verifying it against retrieved evidence.\n",
        "\n",
        "Developed a retrieval-grounded hallucination detection system that verifies LLM outputs against external evidence using FAISS + embeddings\n",
        "\n",
        "Implemented an LLM-based fact-checker to classify responses as Supported, Partially Supported, or Hallucinated\n",
        "\n",
        "Pipeline Flow\n",
        "\n",
        "1️⃣ User Question\n",
        "2️⃣ LLM generates answer (baseline)\n",
        "3️⃣ Retriever fetches relevant documents (RAG step)\n",
        "4️⃣ Fact-Checker LLM compares answer vs retrieved evidence\n",
        "5️⃣ Output label:\n",
        "\n",
        "✅ Supported\n",
        "\n",
        "⚠️ Partially Supported\n",
        "\n",
        "❌ Hallucinated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62eOdlIdL8Wj",
        "outputId": "e1abad67-6417-4097-88d8-ac06ce564624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.16.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install openai faiss-cpu numpy pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO3XBHCyMD3c"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pandas as pd\n",
        "\n",
        "# add youur key here\n",
        "client = OpenAI(api_key=)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NFf2zpisME-y"
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    \"Python was created by Guido van Rossum and first released in 1991.\",\n",
        "    \"FAISS was developed by Meta (Facebook AI Research).\",\n",
        "    \"There is no Nobel Prize category for Artificial Intelligence.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7uD9ePizMIOq"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text):\n",
        "    response = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "doc_embeddings = [get_embedding(doc) for doc in documents]\n",
        "dimension = len(doc_embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Gn4QI3m0MPKc"
      },
      "outputs": [],
      "source": [
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(doc_embeddings).astype(\"float32\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "f4pSOS-qMQEn"
      },
      "outputs": [],
      "source": [
        "def generate_baseline_answer(question):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": question}]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6J5xr7sRMSH_"
      },
      "outputs": [],
      "source": [
        "def retrieve_evidence(question, k=2):\n",
        "    q_embedding = np.array([get_embedding(question)]).astype(\"float32\")\n",
        "    distances, indices = index.search(q_embedding, k)\n",
        "    retrieved_docs = [documents[i] for i in indices[0]]\n",
        "    return \"\\n\".join(retrieved_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nP6zNiGKMTyV"
      },
      "outputs": [],
      "source": [
        "def detect_hallucination(question, answer, evidence):\n",
        "    prompt = f\"\"\"\n",
        "You are a fact-checking AI.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Model Answer: {answer}\n",
        "\n",
        "Evidence:\n",
        "{evidence}\n",
        "\n",
        "Classify the answer as:\n",
        "- Supported\n",
        "- Partially Supported\n",
        "- Hallucinated\n",
        "\n",
        "Return only the label.\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwudP2oRMWbq",
        "outputId": "9668cfab-35db-4ee8-9a66-1d20eb4733d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            Question  \\\n",
            "0  Who invented the Python programming language i...   \n",
            "1    What company created the FAISS vector database?   \n",
            "2  Which country first used Retrieval-Augmented G...   \n",
            "\n",
            "                                     Baseline Answer  \\\n",
            "0  The Python programming language was invented b...   \n",
            "1  FAISS (Facebook AI Similarity Search) was deve...   \n",
            "2  The first country to explicitly incorporate Re...   \n",
            "\n",
            "                                  Retrieved Evidence  Hallucination Label  \n",
            "0  Python was created by Guido van Rossum and fir...            Supported  \n",
            "1  FAISS was developed by Meta (Facebook AI Resea...            Supported  \n",
            "2  FAISS was developed by Meta (Facebook AI Resea...  Partially Supported  \n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    \"Who invented the Python programming language in 1995?\",\n",
        "    \"What company created the FAISS vector database?\",\n",
        "    \"Which country first used Retrieval-Augmented Generation in national AI policy?\",\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for q in questions:\n",
        "    baseline_answer = generate_baseline_answer(q)\n",
        "    evidence = retrieve_evidence(q)\n",
        "    label = detect_hallucination(q, baseline_answer, evidence)\n",
        "\n",
        "    results.append({\n",
        "        \"Question\": q,\n",
        "        \"Baseline Answer\": baseline_answer,\n",
        "        \"Retrieved Evidence\": evidence,\n",
        "        \"Hallucination Label\": label\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(df)\n",
        "df.to_csv(\"hallucination_detection_results.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
